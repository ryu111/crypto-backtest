"""
è³‡æ–™é©—è­‰æ¨¡çµ„

åœ¨å›æ¸¬å‰é©—è­‰è³‡æ–™å“è³ªï¼Œé¿å…å› è³‡æ–™å•é¡Œå°è‡´éŒ¯èª¤çš„å›æ¸¬çµæœã€‚

åƒè€ƒï¼š
- .claude/skills/è³‡æ–™ç®¡é“/SKILL.md

ä½¿ç”¨ç¯„ä¾‹ï¼š
    validator = DataValidator()

    # å›æ¸¬å‰é©—è­‰
    issues = validator.validate(data)

    if validator.has_fatal_issues(issues):
        raise ValueError("è³‡æ–™æœ‰åš´é‡å•é¡Œï¼Œç„¡æ³•åŸ·è¡Œå›æ¸¬")

    # è‡ªå‹•ä¿®å¾©
    if validator.has_fixable_issues(issues):
        data = validator.auto_fix(data, issues)
"""

from dataclasses import dataclass
from typing import List, Optional, Any, Literal
from enum import Enum
import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__)


class IssueLevel(Enum):
    """å•é¡Œåš´é‡ç­‰ç´š"""
    FATAL = "fatal"       # è‡´å‘½ï¼šé˜»æ­¢å›æ¸¬
    WARNING = "warning"   # è­¦å‘Šï¼šè¨˜éŒ„ä¸¦å¯ä¿®å¾©
    INFO = "info"         # è³‡è¨Šï¼šåƒ…è¨˜éŒ„


@dataclass
class DataIssue:
    """è³‡æ–™å•é¡Œè¨˜éŒ„"""
    level: IssueLevel
    issue_type: str
    count: int
    details: Any
    fixable: bool = False

    @property
    def message(self) -> str:
        """å•é¡Œè¨Šæ¯"""
        level_emoji = {
            IssueLevel.FATAL: "âŒ",
            IssueLevel.WARNING: "âš ï¸",
            IssueLevel.INFO: "â„¹ï¸"
        }
        emoji = level_emoji.get(self.level, "")
        fix_hint = " (å¯è‡ªå‹•ä¿®å¾©)" if self.fixable else ""
        return f"{emoji} [{self.level.value.upper()}] {self.issue_type}: {self.count} ç­†{fix_hint}"


class DataValidator:
    """
    è³‡æ–™é©—è­‰å™¨

    é©—è­‰ OHLCV è³‡æ–™å“è³ªï¼Œè­˜åˆ¥ä¸¦ä¿®å¾©å¸¸è¦‹å•é¡Œã€‚

    å•é¡Œå„ªå…ˆç´šï¼š
    - FATALï¼šç¼ºå¤±å€¼ã€OHLC é‚è¼¯éŒ¯èª¤ï¼ˆé˜»æ­¢å›æ¸¬ï¼‰
    - WARNINGï¼šæ™‚é–“é–“éš™ã€é‡è¤‡æ™‚é–“æˆ³ï¼ˆè¨˜éŒ„ä¸¦ä¿®å¾©ï¼‰
    - INFOï¼šä½æˆäº¤é‡ï¼ˆåƒ…è¨˜éŒ„ï¼‰
    """

    def __init__(
        self,
        allow_auto_fix: bool = True,
        low_volume_threshold: float = 0.1  # ä½æ–¼å¹³å‡çš„ 10%
    ):
        """
        åˆå§‹åŒ–é©—è­‰å™¨

        Args:
            allow_auto_fix: æ˜¯å¦å…è¨±è‡ªå‹•ä¿®å¾©
            low_volume_threshold: ä½æˆäº¤é‡é–¾å€¼ï¼ˆç›¸å°æ–¼å¹³å‡ï¼‰
        """
        self.allow_auto_fix = allow_auto_fix
        self.low_volume_threshold = low_volume_threshold

    def validate(self, df: pd.DataFrame) -> List[DataIssue]:
        """
        é©—è­‰è³‡æ–™å“è³ª

        Args:
            df: OHLCV DataFrame

        Returns:
            å•é¡Œåˆ—è¡¨
        """
        issues = []

        # 1. æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        missing_cols = set(required_cols) - set(df.columns)
        if missing_cols:
            issues.append(DataIssue(
                level=IssueLevel.FATAL,
                issue_type="missing_columns",
                count=len(missing_cols),
                details=list(missing_cols),
                fixable=False
            ))
            return issues  # ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œç„¡æ³•ç¹¼çºŒé©—è­‰

        # 2. æª¢æŸ¥ç¼ºå¤±å€¼ï¼ˆFATALï¼‰
        null_counts = df[required_cols].isnull().sum()
        total_nulls = null_counts.sum()
        if total_nulls > 0:
            issues.append(DataIssue(
                level=IssueLevel.FATAL,
                issue_type="null_values",
                count=int(total_nulls),
                details=null_counts.to_dict(),
                fixable=True  # å¯ç”¨å‰å‘å¡«å……ä¿®å¾©
            ))

        # 3. æª¢æŸ¥ OHLC é‚è¼¯ï¼ˆFATALï¼‰
        ohlc_errors = self._check_ohlc_logic(df)
        if ohlc_errors > 0:
            issues.append(DataIssue(
                level=IssueLevel.FATAL,
                issue_type="invalid_ohlc_logic",
                count=ohlc_errors,
                details="H < max(O,C) æˆ– L > min(O,C)",
                fixable=True  # å¯ä¿®æ­£
            ))

        # 4. æª¢æŸ¥æ™‚é–“é€£çºŒæ€§ï¼ˆWARNINGï¼‰
        time_gaps = self._check_time_continuity(df)
        if time_gaps > 0:
            issues.append(DataIssue(
                level=IssueLevel.WARNING,
                issue_type="time_gaps",
                count=time_gaps,
                details=self._find_gaps(df),
                fixable=True  # å¯æ’è£œ
            ))

        # 5. æª¢æŸ¥é‡è¤‡æ™‚é–“æˆ³ï¼ˆWARNINGï¼‰
        duplicates = df.index.duplicated().sum()
        if duplicates > 0:
            issues.append(DataIssue(
                level=IssueLevel.WARNING,
                issue_type="duplicate_timestamps",
                count=int(duplicates),
                details=df.index[df.index.duplicated()].tolist()[:10],
                fixable=True  # å¯ç§»é™¤
            ))

        # 6. æª¢æŸ¥æˆäº¤é‡ï¼ˆINFOï¼‰
        zero_volume = (df['volume'] <= 0).sum()
        if zero_volume > 0:
            issues.append(DataIssue(
                level=IssueLevel.WARNING,
                issue_type="zero_or_negative_volume",
                count=int(zero_volume),
                details="æˆäº¤é‡ç‚ºé›¶æˆ–è² æ•¸",
                fixable=False
            ))

        # 7. æª¢æŸ¥ä½æˆäº¤é‡ï¼ˆINFOï¼‰
        low_volume = self._check_low_volume(df)
        if low_volume > 0:
            issues.append(DataIssue(
                level=IssueLevel.INFO,
                issue_type="low_volume",
                count=low_volume,
                details=f"ä½æ–¼å¹³å‡çš„ {self.low_volume_threshold*100}%",
                fixable=False
            ))

        return issues

    def _check_ohlc_logic(self, df: pd.DataFrame) -> int:
        """æª¢æŸ¥ OHLC é‚è¼¯"""
        invalid = (
            (df['high'] < df['open']) |
            (df['high'] < df['close']) |
            (df['low'] > df['open']) |
            (df['low'] > df['close']) |
            (df['high'] < df['low'])
        )
        return int(invalid.sum())

    def _check_time_continuity(self, df: pd.DataFrame) -> int:
        """æª¢æŸ¥æ™‚é–“é€£çºŒæ€§"""
        if len(df) < 2:
            return 0

        time_diff = df.index.to_series().diff()
        expected_freq = time_diff.mode().iloc[0] if len(time_diff.mode()) > 0 else time_diff.median()

        # å…è¨± 10% çš„èª¤å·®
        gaps = time_diff > expected_freq * 1.5
        return int(gaps.sum())

    def _find_gaps(self, df: pd.DataFrame) -> List[dict]:
        """æ‰¾å‡ºæ™‚é–“é–“éš™"""
        if len(df) < 2:
            return []

        time_diff = df.index.to_series().diff()
        expected_freq = time_diff.mode().iloc[0] if len(time_diff.mode()) > 0 else time_diff.median()

        gaps = time_diff > expected_freq * 1.5
        gap_indices = df.index[gaps]

        return [
            {
                'start': str(df.index[i-1]) if i > 0 else None,
                'end': str(idx),
                'gap_size': str(time_diff.iloc[i])
            }
            for i, idx in enumerate(df.index) if idx in gap_indices
        ][:10]  # æœ€å¤šé¡¯ç¤º 10 å€‹

    def _check_low_volume(self, df: pd.DataFrame) -> int:
        """æª¢æŸ¥ä½æˆäº¤é‡"""
        if 'volume' not in df.columns:
            return 0

        avg_volume = df['volume'].mean()
        threshold = avg_volume * self.low_volume_threshold
        low_volume = df['volume'] < threshold
        return int(low_volume.sum())

    def validate_before_backtest(self, df: pd.DataFrame) -> bool:
        """
        å›æ¸¬å‰å¼·åˆ¶é©—è­‰

        Args:
            df: OHLCV DataFrame

        Returns:
            æ˜¯å¦å¯ä»¥åŸ·è¡Œå›æ¸¬

        Raises:
            ValueError: å¦‚æœæœ‰ FATAL å•é¡Œ
        """
        issues = self.validate(df)

        # è¨˜éŒ„æ‰€æœ‰å•é¡Œ
        for issue in issues:
            if issue.level == IssueLevel.FATAL:
                logger.error(issue.message)
            elif issue.level == IssueLevel.WARNING:
                logger.warning(issue.message)
            else:
                logger.info(issue.message)

        # æª¢æŸ¥æ˜¯å¦æœ‰ FATAL å•é¡Œ
        fatal_issues = [i for i in issues if i.level == IssueLevel.FATAL]
        if fatal_issues:
            if not self.allow_auto_fix or not all(i.fixable for i in fatal_issues):
                raise ValueError(
                    f"è³‡æ–™æœ‰ {len(fatal_issues)} å€‹åš´é‡å•é¡Œï¼Œç„¡æ³•åŸ·è¡Œå›æ¸¬ï¼š" +
                    ", ".join(i.issue_type for i in fatal_issues)
                )
            return False  # éœ€è¦ä¿®å¾©

        return True

    def auto_fix(
        self,
        df: pd.DataFrame,
        issues: Optional[List[DataIssue]] = None
    ) -> pd.DataFrame:
        """
        è‡ªå‹•ä¿®å¾©è³‡æ–™å•é¡Œ

        Args:
            df: OHLCV DataFrame
            issues: å•é¡Œåˆ—è¡¨ï¼ˆå¯é¸ï¼Œå¦å‰‡è‡ªå‹•é©—è­‰ï¼‰

        Returns:
            ä¿®å¾©å¾Œçš„ DataFrame
        """
        if issues is None:
            issues = self.validate(df)

        df_fixed = df.copy()

        for issue in issues:
            if not issue.fixable:
                continue

            if issue.issue_type == "duplicate_timestamps":
                # ç§»é™¤é‡è¤‡æ™‚é–“æˆ³
                df_fixed = df_fixed[~df_fixed.index.duplicated(keep='first')]
                logger.info(f"å·²ç§»é™¤ {issue.count} å€‹é‡è¤‡æ™‚é–“æˆ³")

            elif issue.issue_type == "null_values":
                # å‰å‘å¡«å……ç¼ºå¤±å€¼
                df_fixed = df_fixed.ffill()
                # å¦‚æœé–‹é ­æœ‰ NaNï¼Œç”¨å¾Œå‘å¡«å……
                df_fixed = df_fixed.bfill()
                logger.info(f"å·²å¡«å…… {issue.count} å€‹ç¼ºå¤±å€¼")

            elif issue.issue_type == "invalid_ohlc_logic":
                # ä¿®æ­£ OHLC é‚è¼¯
                df_fixed['high'] = df_fixed[['open', 'high', 'close']].max(axis=1)
                df_fixed['low'] = df_fixed[['open', 'low', 'close']].min(axis=1)
                logger.info(f"å·²ä¿®æ­£ {issue.count} å€‹ OHLC é‚è¼¯éŒ¯èª¤")

            elif issue.issue_type == "time_gaps":
                # æ’è£œç¼ºå¤±çš„æ™‚é–“æˆ³
                df_fixed = self._fill_time_gaps(df_fixed)
                logger.info(f"å·²æ’è£œ {issue.count} å€‹æ™‚é–“é–“éš™")

        # ç¢ºä¿æ’åº
        df_fixed = df_fixed.sort_index()

        return df_fixed

    def _fill_time_gaps(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¡«è£œæ™‚é–“é–“éš™"""
        try:
            # æ¨æ–·é »ç‡
            freq = pd.infer_freq(df.index)
            if freq is None:
                # ä½¿ç”¨æœ€å¸¸è¦‹çš„æ™‚é–“å·®
                time_diff = df.index.to_series().diff()
                freq = time_diff.mode().iloc[0]

            # ç”Ÿæˆå®Œæ•´çš„æ™‚é–“ç´¢å¼•
            full_index = pd.date_range(
                start=df.index.min(),
                end=df.index.max(),
                freq=freq
            )

            # é‡æ–°ç´¢å¼•ä¸¦å‰å‘å¡«å……
            df_filled = df.reindex(full_index, method='ffill')
            return df_filled

        except Exception as e:
            logger.warning(f"ç„¡æ³•å¡«è£œæ™‚é–“é–“éš™: {e}")
            return df

    def has_fatal_issues(self, issues: List[DataIssue]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰ FATAL å•é¡Œ"""
        return any(i.level == IssueLevel.FATAL for i in issues)

    def has_fixable_issues(self, issues: List[DataIssue]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¯ä¿®å¾©çš„å•é¡Œ"""
        return any(i.fixable for i in issues)

    def summary(self, issues: List[DataIssue]) -> str:
        """ç”Ÿæˆå•é¡Œæ‘˜è¦"""
        if not issues:
            return "âœ… è³‡æ–™å“è³ªè‰¯å¥½ï¼Œç„¡å•é¡Œ"

        fatal = [i for i in issues if i.level == IssueLevel.FATAL]
        warning = [i for i in issues if i.level == IssueLevel.WARNING]
        info = [i for i in issues if i.level == IssueLevel.INFO]

        lines = ["ğŸ“Š è³‡æ–™å“è³ªå ±å‘Š", "=" * 40]

        if fatal:
            lines.append(f"\nâŒ åš´é‡å•é¡Œ ({len(fatal)})")
            for i in fatal:
                lines.append(f"  - {i.issue_type}: {i.count} ç­†")

        if warning:
            lines.append(f"\nâš ï¸ è­¦å‘Š ({len(warning)})")
            for i in warning:
                lines.append(f"  - {i.issue_type}: {i.count} ç­†")

        if info:
            lines.append(f"\nâ„¹ï¸ è³‡è¨Š ({len(info)})")
            for i in info:
                lines.append(f"  - {i.issue_type}: {i.count} ç­†")

        fixable = [i for i in issues if i.fixable]
        if fixable:
            lines.append(f"\nğŸ”§ å¯è‡ªå‹•ä¿®å¾©: {len(fixable)} é …")

        return "\n".join(lines)


def validate_ohlcv(df: pd.DataFrame) -> List[DataIssue]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šé©—è­‰ OHLCV è³‡æ–™

    Args:
        df: OHLCV DataFrame

    Returns:
        å•é¡Œåˆ—è¡¨
    """
    validator = DataValidator()
    return validator.validate(df)
