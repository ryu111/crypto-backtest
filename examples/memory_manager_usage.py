"""
è¨˜æ†¶é«”ç®¡ç†å™¨ä½¿ç”¨ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•åœ¨å›æ¸¬ç³»çµ±ä¸­ä½¿ç”¨è¨˜æ†¶é«”ç®¡ç†å™¨ä¾†å„ªåŒ–æ•ˆèƒ½ã€‚
"""

from datetime import datetime, timedelta
from pathlib import Path

import numpy as np

from src.data.memory_manager import SharedMemoryPool, UnifiedMemoryManager


# ç¯„ä¾‹ 1: åŸºæœ¬ä½¿ç”¨ - é è¼‰å…¥è³‡æ–™
def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ï¼šé è¼‰å…¥å¤šå¹´è³‡æ–™"""
    print("=== ç¯„ä¾‹ 1: åŸºæœ¬ä½¿ç”¨ ===\n")

    # å»ºç«‹è¨˜æ†¶é«”ç®¡ç†å™¨ï¼ˆä½¿ç”¨ 48GB å¿«å–ï¼‰
    manager = UnifiedMemoryManager(max_cache_gb=48.0)

    # æ¨¡æ“¬è³‡æ–™è¼‰å…¥å‡½æ•¸
    def load_ohlcv_data(symbol, timeframe, start_date, end_date):
        """è¼‰å…¥ OHLCV è³‡æ–™ï¼ˆé€™è£¡ç”¨éš¨æ©Ÿè³‡æ–™æ¨¡æ“¬ï¼‰"""
        days = (end_date - start_date).days
        rows = days * 1440  # å‡è¨­ 1 åˆ†é˜è³‡æ–™
        # å¯¦éš›æ‡‰è©²å¾ database æˆ– CSV è®€å–
        return np.random.rand(rows, 6)  # [timestamp, open, high, low, close, volume]

    # é è¼‰å…¥ 2 å¹´è³‡æ–™
    symbols = ["BTCUSDT", "ETHUSDT"]
    timeframes = ["1m", "5m", "15m"]
    start_date = datetime(2022, 1, 1)
    end_date = datetime(2024, 1, 1)

    print(f"é è¼‰å…¥è³‡æ–™: {symbols} x {timeframes}")
    print(f"æ™‚é–“ç¯„åœ: {start_date.date()} ~ {end_date.date()}\n")

    preloaded = manager.preload_data(
        symbols=symbols,
        timeframes=timeframes,
        start_date=start_date,
        end_date=end_date,
        data_loader_fn=load_ohlcv_data,
    )

    # é¡¯ç¤ºå·²è¼‰å…¥çš„è³‡æ–™
    total_size_gb = sum(arr.nbytes for arr in preloaded.values()) / (1024**3)
    print(f"å·²è¼‰å…¥ {len(preloaded)} çµ„è³‡æ–™")
    print(f"ç¸½å¤§å°: {total_size_gb:.2f} GB\n")

    # å–å¾—è¨˜æ†¶é«”çµ±è¨ˆ
    stats = manager.get_stats()
    print(stats)


# ç¯„ä¾‹ 2: é›¶æ‹·è²è³‡æ–™å…±äº«
def example_zero_copy():
    """é›¶æ‹·è²è³‡æ–™å…±äº«ï¼ˆé¿å…é‡è¤‡è¨˜æ†¶é«”ä½¿ç”¨ï¼‰"""
    print("\n=== ç¯„ä¾‹ 2: é›¶æ‹·è²è³‡æ–™å…±äº« ===\n")

    manager = UnifiedMemoryManager(max_cache_gb=10.0)

    # æ¨¡æ“¬è¼‰å…¥å¤§å‹è³‡æ–™
    large_data = np.random.rand(1000000, 6)  # 48 MB
    print(f"åŸå§‹è³‡æ–™å¤§å°: {large_data.nbytes / 1024**2:.2f} MB")

    # å„ªåŒ–ä¸¦å¿«å–
    optimized = manager.optimize_for_gpu(large_data)
    manager._cache["BTCUSDT_1m_2024"] = optimized

    # å–å¾—å…±äº«é™£åˆ—ï¼ˆé›¶æ‹·è²ï¼‰
    shared_array = manager.get_shared_array("BTCUSDT_1m_2024")

    # é©—è­‰é›¶æ‹·è²
    is_zero_copy = manager.verify_zero_copy("BTCUSDT_1m_2024")
    print(f"é›¶æ‹·è²é©—è­‰: {'âœ“ æˆåŠŸ' if is_zero_copy else 'âœ— å¤±æ•—'}")

    # é©—è­‰è¨˜æ†¶é«”å…±äº«
    shares_memory = np.shares_memory(optimized, shared_array)
    print(f"è¨˜æ†¶é«”å…±äº«: {'âœ“ æ˜¯' if shares_memory else 'âœ— å¦'}")

    # ä¿®æ”¹ shared_array æœƒå½±éŸ¿ optimizedï¼ˆè­‰æ˜æ˜¯åŒä¸€å¡Šè¨˜æ†¶é«”ï¼‰
    original_value = shared_array[0, 0]
    shared_array[0, 0] = 999.0
    print(f"\nä¿®æ”¹ shared_array[0,0] = 999.0")
    print(f"optimized[0,0] = {optimized[0, 0]} (æ‡‰è©²ä¹Ÿæ˜¯ 999.0)")
    shared_array[0, 0] = original_value  # æ¢å¾©


# ç¯„ä¾‹ 3: Memory-mapped filesï¼ˆè¶…å¤§è³‡æ–™é›†ï¼‰
def example_memory_mapped():
    """ä½¿ç”¨ memory-mapped files è™•ç†è¶…é RAM çš„è³‡æ–™"""
    print("\n=== ç¯„ä¾‹ 3: Memory-mapped Files ===\n")

    manager = UnifiedMemoryManager()

    # å»ºç«‹è‡¨æ™‚æª”æ¡ˆ
    mmap_file = Path("/tmp/large_dataset.npy")

    # å»ºç«‹è¶…å¤§è³‡æ–™é›†ï¼ˆåªä½”ç”¨å°‘é‡ RAMï¼‰
    shape = (10000000, 6)  # 480 MB
    dtype = np.float64

    print(f"å»ºç«‹ memory-mapped é™£åˆ—: {shape}")
    print(f"ç†è«–å¤§å°: {np.prod(shape) * dtype(0).nbytes / 1024**2:.2f} MB")

    # å»ºç«‹ memory-mapped é™£åˆ—
    mmap_array = manager.create_mmap_array(mmap_file, shape, dtype, mode="w+")

    # å¯«å…¥è³‡æ–™ï¼ˆåˆ†æ‰¹å¯«å…¥ï¼Œé¿å…ä¸€æ¬¡æ€§è¼‰å…¥å…¨éƒ¨ï¼‰
    batch_size = 100000
    for i in range(0, shape[0], batch_size):
        end = min(i + batch_size, shape[0])
        mmap_array[i:end] = np.random.rand(end - i, shape[1])

    print(f"âœ“ è³‡æ–™å¯«å…¥å®Œæˆ")
    print(f"å¯¦éš› RAM ä½¿ç”¨: æ¥µå°‘ï¼ˆè³‡æ–™å„²å­˜åœ¨ç¡¬ç¢Ÿï¼‰\n")

    # è®€å–éƒ¨åˆ†è³‡æ–™
    sample = mmap_array[0:1000]  # åªè¼‰å…¥å‰ 1000 è¡Œåˆ° RAM
    print(f"è®€å–æ¨£æœ¬: {sample.shape}")

    # æ¸…ç†
    mmap_file.unlink()


# ç¯„ä¾‹ 4: è·¨é€²ç¨‹å…±äº«è¨˜æ†¶é«”ï¼ˆå¤šé€²ç¨‹å›æ¸¬ï¼‰
def example_shared_memory_pool():
    """è·¨é€²ç¨‹å…±äº«è¨˜æ†¶é«”æ± ï¼ˆç”¨æ–¼ä¸¦è¡Œå›æ¸¬ï¼‰"""
    print("\n=== ç¯„ä¾‹ 4: è·¨é€²ç¨‹å…±äº«è¨˜æ†¶é«” ===\n")

    # å»ºç«‹å…±äº«è¨˜æ†¶é«”æ± 
    pool = SharedMemoryPool(name="backtest_data", size_gb=1.0)

    try:
        pool.create()
        print("âœ“ å…±äº«è¨˜æ†¶é«”æ± å·²å»ºç«‹\n")

        # ä¸»é€²ç¨‹ï¼šè¼‰å…¥è³‡æ–™åˆ°å…±äº«è¨˜æ†¶é«”
        btc_data = np.random.rand(100000, 6)
        eth_data = np.random.rand(100000, 6)

        pool.put("BTCUSDT", btc_data, offset=0)
        pool.put("ETHUSDT", eth_data, offset=btc_data.nbytes)

        print(f"å·²æ”¾å…¥è³‡æ–™:")
        print(f"  BTCUSDT: {btc_data.nbytes / 1024**2:.2f} MB")
        print(f"  ETHUSDT: {eth_data.nbytes / 1024**2:.2f} MB\n")

        # å­é€²ç¨‹å¯ä»¥é™„åŠ åˆ°ç›¸åŒçš„å…±äº«è¨˜æ†¶é«”
        # é€™è£¡æ¨¡æ“¬å–å¾—è³‡æ–™ï¼ˆå¯¦éš›ä½¿ç”¨æ™‚åœ¨å­é€²ç¨‹åŸ·è¡Œï¼‰
        retrieved_btc = pool.get("BTCUSDT")
        retrieved_eth = pool.get("ETHUSDT")

        # é©—è­‰
        assert np.array_equal(retrieved_btc, btc_data)
        assert np.array_equal(retrieved_eth, eth_data)

        print("âœ“ è³‡æ–™é©—è­‰æˆåŠŸ")
        print("å­é€²ç¨‹å¯ä»¥é›¶æ‹·è²å­˜å–ç›¸åŒè³‡æ–™")

    finally:
        pool.close()
        pool.unlink()


# ç¯„ä¾‹ 5: æ•ˆèƒ½æ¯”è¼ƒï¼ˆå‚³çµ± vs é›¶æ‹·è²ï¼‰
def example_performance_comparison():
    """æ•ˆèƒ½æ¯”è¼ƒï¼šå‚³çµ±è¤‡è£½ vs é›¶æ‹·è²"""
    import time

    print("\n=== ç¯„ä¾‹ 5: æ•ˆèƒ½æ¯”è¼ƒ ===\n")

    manager = UnifiedMemoryManager()
    large_data = np.random.rand(5000000, 6)  # 240 MB

    # å„ªåŒ–ä¸¦å¿«å–
    optimized = manager.optimize_for_gpu(large_data)
    manager._cache["test_data"] = optimized

    # æ¸¬è©¦ 1: å‚³çµ±è¤‡è£½
    iterations = 100
    start = time.time()
    for _ in range(iterations):
        copy = large_data.copy()  # å®Œæ•´è¤‡è£½
    copy_time = time.time() - start

    # æ¸¬è©¦ 2: é›¶æ‹·è²
    start = time.time()
    for _ in range(iterations):
        shared = manager.get_shared_array("test_data")  # é›¶æ‹·è²
    zero_copy_time = time.time() - start

    print(f"è³‡æ–™å¤§å°: {large_data.nbytes / 1024**2:.2f} MB")
    print(f"è¿­ä»£æ¬¡æ•¸: {iterations}\n")

    print(f"å‚³çµ±è¤‡è£½: {copy_time:.3f} ç§’")
    print(f"é›¶æ‹·è²:   {zero_copy_time:.6f} ç§’")
    print(f"\nåŠ é€Ÿå€æ•¸: {copy_time / zero_copy_time:.0f}x ğŸš€")


# ä¸»ç¨‹å¼
if __name__ == "__main__":
    # åŸ·è¡Œæ‰€æœ‰ç¯„ä¾‹
    example_basic_usage()
    example_zero_copy()
    example_memory_mapped()
    example_shared_memory_pool()
    example_performance_comparison()

    print("\n=== æ‰€æœ‰ç¯„ä¾‹å®Œæˆ ===")
